{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation steering with TransformerLens and gpt2\n",
    "\n",
    "This notebook shows how to access and modify internal model activations using the transformer lens library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# load transformer lens model\n",
    "model = HookedTransformer.from_pretrained_no_processing(\"gpt2\", default_prepend_bos=False).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_love.shape: torch.Size([1, 1, 768])\n",
      "act_hate.shape: torch.Size([1, 2, 768])\n"
     ]
    }
   ],
   "source": [
    "# define what layer/module you want information from and get the internal activations\n",
    "layer_id = 6\n",
    "cache_name = f\"blocks.{layer_id}.hook_resid_post\" # we do activation steering on the activation (the output) of the residual layer\n",
    "\n",
    "_, cache = model.run_with_cache(\"Love\")\n",
    "act_love = cache[cache_name]\n",
    "_, cache = model.run_with_cache(\"Hate\")\n",
    "act_hate = cache[cache_name]\n",
    "\n",
    "print(f\"act_love.shape: {act_love.shape}\")\n",
    "print(f\"act_hate.shape: {act_hate.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by looking at the shape of the activation tensors, the input \"sentences\" are tokenized into different numbers of tokens. To make this into a vector we only take the numerical values of the last token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_vec.shape:  torch.Size([1, 1, 768])\n",
      "length steering_vec: 3044.24\n"
     ]
    }
   ],
   "source": [
    "# define the steering vector\n",
    "steering_vec = act_love[:,-1:,:]-act_hate[:,-1:,:]\n",
    "print(f\"steering_vec.shape:  {steering_vec.shape}\")\n",
    "print(f\"length steering_vec: {steering_vec.norm():.2f}\")\n",
    "\n",
    "# reset the steering vector length to 1\n",
    "steering_vec /= steering_vec.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the activation steering funtion\n",
    "def act_add(steering_vec):\n",
    "    def hook(activation, hook):\n",
    "        return activation + steering_vec\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously used the function `run_with_cache` to get the internal activations. This function adds PyTorch hooks before running the model and removes them afterwards.\n",
    "There is also the function `run_with_hooks` for which you can set your own hook functions. However I did not find a function `generate_with_hooks`.\n",
    "\n",
    "If we want to generate new text, the model needs to repeatedly perform a forward pass and we want our activation addition to happen in each forward pass. We consequently need to set a hook that does the activation addition. After we generated our text it is important to remove the hook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think dogs are icky, and they're not going to be able\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 28.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think dogs are icky, and I think dogs are icky,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I think dogs are \"\n",
    "\n",
    "# generate text while steering in positive direction\n",
    "coeff = 10\n",
    "model.add_hook(name=cache_name, hook=act_add(coeff*steering_vec))\n",
    "print(model.generate(test_sentence, max_new_tokens=10, do_sample=False))\n",
    "model.reset_hooks()\n",
    "print(\"-\"*20)\n",
    "\n",
    "# generate text while steering in negative direction\n",
    "coeff = -10\n",
    "test_sentence = \"I think dogs are \"\n",
    "model.add_hook(name=cache_name, hook=act_add(coeff*steering_vec))\n",
    "print(model.generate(test_sentence, max_new_tokens=10, do_sample=False))\n",
    "model.reset_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think dogs are icky, and I think dogs are icky,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate text without steering\n",
    "print(model.generate(test_sentence, max_new_tokens=10, do_sample=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp-final-project (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

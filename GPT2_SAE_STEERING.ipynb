{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sae-lens\n",
      "  Downloading sae_lens-6.22.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting transformer_lens\n",
      "  Downloading transformer_lens-2.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sae-dashboard\n",
      "  Downloading sae_dashboard-0.7.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting babe<0.0.8,>=0.0.7 (from sae-lens)\n",
      "  Downloading babe-0.0.7-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: datasets>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (4.0.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (3.9.1)\n",
      "Requirement already satisfied: plotly>=5.19.0 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (5.24.1)\n",
      "Collecting plotly-express>=0.4.1 (from sae-lens)\n",
      "  Downloading plotly_express-0.4.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (1.2.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (6.0.3)\n",
      "Requirement already satisfied: safetensors<1.0.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (0.6.2)\n",
      "Requirement already satisfied: simple-parsing<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (0.1.7)\n",
      "Collecting tenacity>=9.0.0 (from sae-lens)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (4.57.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from sae-lens) (4.15.0)\n",
      "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (1.11.0)\n",
      "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
      "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
      "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.8.1)\n",
      "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
      "  Downloading jaxtyping-0.3.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting numpy<2,>=1.26 (from transformer_lens)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (2.2.2)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (13.9.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.2.1)\n",
      "Requirement already satisfied: torch>=2.6 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (2.8.0+cu126)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.67.1)\n",
      "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer_lens)\n",
      "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (4.4.4)\n",
      "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.12/dist-packages (from transformer_lens) (0.22.3)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.4 (from sae-dashboard)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting datasets>=3.1.0 (from sae-lens)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting decode-clt<0.0.2,>=0.0.1 (from sae-dashboard)\n",
      "  Downloading decode_clt-0.0.1-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting eindex-callum<0.2.0,>=0.1.0 (from sae-dashboard)\n",
      "  Downloading eindex_callum-0.1.2-py3-none-any.whl.metadata (377 bytes)\n",
      "Requirement already satisfied: hf-transfer<0.2.0,>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from sae-dashboard) (0.1.9)\n",
      "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
      "  Downloading jaxtyping-0.2.38-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.8.4 in /usr/local/lib/python3.12/dist-packages (from sae-dashboard) (3.10.0)\n",
      "Collecting safetensors<1.0.0,>=0.4.2 (from sae-lens)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting transformers<5.0.0,>=4.38.1 (from sae-lens)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typer<0.13.0,>=0.12.3 (from sae-dashboard)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.36.0)\n",
      "Collecting py2store (from babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Downloading py2store-0.1.22.tar.gz (145 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.1/145.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting graze (from babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Downloading graze-0.1.39-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.4->sae-dashboard)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.4->sae-dashboard)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.1.0->sae-lens) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.1.0->sae-lens) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.1.0->sae-lens) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.1.0->sae-lens) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.1.0->sae-lens) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.1.0->sae-lens) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (2025.3.0)\n",
      "Requirement already satisfied: torchvision>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from decode-clt<0.0.2,>=0.0.1->sae-dashboard) (2.8.0+cu126)\n",
      "Collecting nnsight>=0.1.0 (from decode-clt<0.0.2,>=0.0.1->sae-dashboard)\n",
      "  Downloading nnsight-0.5.10-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.12/dist-packages (from decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.25.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from decode-clt<0.0.2,>=0.0.1->sae-dashboard) (3.15.1)\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
      "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->sae-dashboard) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->sae-dashboard) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->sae-dashboard) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->sae-dashboard) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->sae-dashboard) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->sae-dashboard) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4.0.0,>=3.8.4->sae-dashboard) (2.9.0.post0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens) (2024.11.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from plotly-express>=0.4.1->sae-lens) (0.14.5)\n",
      "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.12/dist-packages (from plotly-express>=0.4.1->sae-lens) (1.16.3)\n",
      "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.12/dist-packages (from plotly-express>=0.4.1->sae-lens) (1.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->transformer_lens) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.6.0->transformer_lens) (2.19.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from simple-parsing<0.2.0,>=0.1.6->sae-lens) (0.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.6->transformer_lens) (3.4.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.38.1->sae-lens) (0.22.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.13.0,>=0.12.3->sae-dashboard) (1.5.4)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (4.5.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (2.11.10)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.13.5->transformer_lens) (2.44.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (3.13.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.23.0->transformer_lens) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Collecting astor (from nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (3.1.2)\n",
      "Collecting python-socketio[client] (from nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard)\n",
      "  Downloading python_socketio-5.14.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.10.2)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (7.34.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.8.4->sae-dashboard) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.1.0->sae-lens) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.1.0->sae-lens) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.1.0->sae-lens) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.1.0->sae-lens) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.6->transformer_lens) (1.3.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.4->sae-dashboard)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting dol (from graze->babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Downloading dol-0.3.31-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.6->transformer_lens) (3.0.3)\n",
      "Collecting config2py (from py2store->babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Downloading config2py-0.1.45-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens) (6.5.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.1.0->sae-lens) (1.22.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
      "Collecting i2 (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens)\n",
      "  Downloading i2-0.1.61-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting jedi>=0.16 (from ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard)\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (3.0.52)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (4.9.0)\n",
      "Collecting bidict>=0.21.0 (from python-socketio[client]->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard)\n",
      "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting python-engineio>=4.11.0 (from python-socketio[client]->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard)\n",
      "  Downloading python_engineio-4.12.3-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.12/dist-packages (from python-socketio[client]->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (1.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.2.14)\n",
      "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio[client]->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard)\n",
      "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio[client]->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard)\n",
      "  Downloading wsproto-1.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio[client]->nnsight>=0.1.0->decode-clt<0.0.2,>=0.0.1->sae-dashboard) (0.16.0)\n",
      "Downloading sae_lens-6.22.2-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.6/160.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformer_lens-2.16.1-py3-none-any.whl (192 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sae_dashboard-0.7.3-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading babe-0.0.7-py3-none-any.whl (6.9 kB)\n",
      "Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading decode_clt-0.0.1-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading eindex_callum-0.1.2-py3-none-any.whl (8.3 kB)\n",
      "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading jaxtyping-0.2.38-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.8/434.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nnsight-0.5.10-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
      "Downloading graze-0.1.39-py3-none-any.whl (30 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading config2py-0.1.45-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dol-0.3.31-py3-none-any.whl (267 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
      "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_engineio-4.12.3-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading i2-0.1.61-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_socketio-5.14.3-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading wsproto-1.3.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: transformers-stream-generator, py2store\n",
      "  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12426 sha256=0351768241501869d85097feec880e29b7ebf10be415844852e95634331c8abb\n",
      "  Stored in directory: /root/.cache/pip/wheels/a8/58/d2/014cb67c3cc6def738c1b1635dbf4e3dab6fb63aba7070dce0\n",
      "  Building wheel for py2store (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py2store: filename=py2store-0.1.22-py3-none-any.whl size=118389 sha256=f5ffa35362eb041531c89abb4ef4a69bdbef406a0e23309dac6df342bb6a7ea0\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/49/01/72e7719a1a5d8d2ed6d557a6b39adc7204094219454c1a15a7\n",
      "Successfully built transformers-stream-generator py2store\n",
      "Installing collected packages: i2, dol, better-abc, wsproto, wadler-lindig, tenacity, safetensors, numpy, mypy-extensions, marshmallow, jedi, fancy-einsum, config2py, bidict, beartype, astor, typing-inspect, simple-websocket, py2store, jaxtyping, graze, typer, python-engineio, dataclasses-json, babe, transformers, python-socketio, plotly-express, eindex-callum, datasets, transformers-stream-generator, transformer_lens, nnsight, sae-lens, decode-clt, sae-dashboard\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.5.0\n",
      "    Uninstalling tenacity-8.5.0:\n",
      "      Successfully uninstalled tenacity-8.5.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.6.2\n",
      "    Uninstalling safetensors-0.6.2:\n",
      "      Successfully uninstalled safetensors-0.6.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: beartype\n",
      "    Found existing installation: beartype 0.22.5\n",
      "    Uninstalling beartype-0.22.5:\n",
      "      Successfully uninstalled beartype-0.22.5\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.20.0\n",
      "    Uninstalling typer-0.20.0:\n",
      "      Successfully uninstalled typer-0.20.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.1\n",
      "    Uninstalling transformers-4.57.1:\n",
      "      Successfully uninstalled transformers-4.57.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "plum-dispatch 2.6.0 requires beartype>=0.16.2, but you have beartype 0.14.1 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "google-adk 1.17.0 requires tenacity<9.0.0,>=8.0.0, but you have tenacity 9.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed astor-0.8.1 babe-0.0.7 beartype-0.14.1 better-abc-0.0.3 bidict-0.23.1 config2py-0.1.45 dataclasses-json-0.6.7 datasets-3.6.0 decode-clt-0.0.1 dol-0.3.31 eindex-callum-0.1.2 fancy-einsum-0.0.3 graze-0.1.39 i2-0.1.61 jaxtyping-0.2.38 jedi-0.19.2 marshmallow-3.26.1 mypy-extensions-1.1.0 nnsight-0.5.10 numpy-1.26.4 plotly-express-0.4.1 py2store-0.1.22 python-engineio-4.12.3 python-socketio-5.14.3 sae-dashboard-0.7.3 sae-lens-6.22.2 safetensors-0.4.5 simple-websocket-1.1.0 tenacity-9.1.2 transformer_lens-2.16.1 transformers-4.56.2 transformers-stream-generator-0.0.5 typer-0.12.5 typing-inspect-0.9.0 wadler-lindig-0.1.7 wsproto-1.3.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "68d81b2bdba141c4a55f41559fdeb7b8",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install sae-lens transformer_lens sae-dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE\n",
    "import torch\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85712637dacd47b890ea3aeb89c64866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bd565cf0234c64936e84a5922044cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd67e4f602045aea7dcce5f6dcebd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb0f9e6dd434d21a70241b642c105d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dff638efa9d4a40b9d61bddaa44bd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a1b63248fd46c2b81ab431b0cb3ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790e85e0e1f6412bae0faa99d06d6f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_gpt2 = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model_gpt2(\"Hello how are\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853cd9e2f6d44e4395432016f57e5cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cfg.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfc8f05159745e595e282bc42b0c004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.8.hook_resid_pre/sae_weights.safe(…):   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39acb676a0b74c3ca6ca8b258f0583fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.8.hook_resid_pre/sparsity.safeten(…):   0%|          | 0.00/98.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sae_lens/saes/sae.py:248: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardSAE(\n",
       "  (activation_fn): ReLU()\n",
       "  (hook_sae_input): HookPoint()\n",
       "  (hook_sae_acts_pre): HookPoint()\n",
       "  (hook_sae_acts_post): HookPoint()\n",
       "  (hook_sae_output): HookPoint()\n",
       "  (hook_sae_recons): HookPoint()\n",
       "  (hook_sae_error): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\",\n",
    "    sae_id=\"blocks.8.hook_resid_pre\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "sae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b5abc4278a4ac39a0c3fa0d488aabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (229134 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "dataset = load_dataset(\n",
    "    path=\"NeelNanda/pile-10k\",\n",
    "    split=\"train\",\n",
    "    streaming=False,\n",
    ")\n",
    "\n",
    "token_dataset = tokenize_and_concatenate(\n",
    "    dataset=dataset,\n",
    "    tokenizer=model_gpt2.tokenizer,\n",
    "    streaming=True,\n",
    "    max_length=sae.cfg.metadata.context_size,\n",
    "    add_bos_token=sae.cfg.metadata.prepend_bos,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = token_dataset[:32][\"tokens\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, cache = model_gpt2.run_with_cache(inputs, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 768])\n"
     ]
    }
   ],
   "source": [
    "print(cache[\"blocks.8.hook_resid_pre\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  features_sae_encoded = sae.encode(cache[sae.cfg.metadata.hook_name])\n",
    "  sae_decoded = sae.decode(features_sae_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 768])\n",
      "torch.Size([32, 128, 24576])\n"
     ]
    }
   ],
   "source": [
    "print(sae_decoded.shape)\n",
    "print(features_sae_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average l0 68.79060363769531\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"f6b7e46a-b4a7-43e6-a872-6eafea55f688\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f6b7e46a-b4a7-43e6-a872-6eafea55f688\")) {                    Plotly.newPlot(                        \"f6b7e46a-b4a7-43e6-a872-6eafea55f688\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"variable=0\\u003cbr\\u003evalue=%{x}\\u003cbr\\u003ecount=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[15.0,25.0,51.0,84.0,88.0,100.0,85.0,60.0,49.0,47.0,36.0,37.0,72.0,88.0,81.0,74.0,50.0,66.0,59.0,38.0,57.0,67.0,38.0,68.0,54.0,68.0,62.0,74.0,66.0,53.0,85.0,76.0,92.0,59.0,73.0,52.0,46.0,51.0,42.0,81.0,49.0,42.0,77.0,90.0,60.0,93.0,70.0,77.0,70.0,59.0,74.0,66.0,71.0,51.0,43.0,44.0,39.0,22.0,30.0,44.0,44.0,34.0,59.0,36.0,52.0,60.0,57.0,45.0,62.0,55.0,75.0,43.0,22.0,37.0,41.0,40.0,60.0,50.0,57.0,74.0,53.0,84.0,120.0,78.0,76.0,67.0,72.0,68.0,101.0,78.0,87.0,99.0,85.0,47.0,48.0,30.0,76.0,65.0,63.0,49.0,45.0,70.0,79.0,76.0,74.0,71.0,66.0,69.0,97.0,81.0,65.0,69.0,83.0,84.0,65.0,58.0,77.0,63.0,66.0,64.0,64.0,72.0,66.0,90.0,75.0,59.0,75.0,27.0,47.0,45.0,55.0,54.0,76.0,66.0,90.0,98.0,66.0,77.0,71.0,79.0,80.0,60.0,63.0,91.0,82.0,65.0,59.0,70.0,63.0,73.0,72.0,63.0,87.0,81.0,78.0,86.0,61.0,59.0,98.0,84.0,65.0,63.0,51.0,63.0,61.0,72.0,78.0,85.0,79.0,75.0,86.0,51.0,37.0,48.0,51.0,49.0,54.0,58.0,67.0,41.0,49.0,68.0,68.0,88.0,40.0,42.0,49.0,90.0,49.0,65.0,87.0,77.0,39.0,75.0,54.0,70.0,57.0,43.0,96.0,51.0,45.0,61.0,63.0,61.0,90.0,52.0,89.0,60.0,77.0,62.0,71.0,62.0,74.0,105.0,89.0,118.0,71.0,67.0,45.0,53.0,58.0,82.0,76.0,45.0,53.0,43.0,71.0,86.0,71.0,51.0,48.0,51.0,84.0,79.0,87.0,78.0,68.0,94.0,74.0,64.0,68.0,38.0,53.0,57.0,57.0,78.0,68.0,39.0,44.0,49.0,57.0,65.0,62.0,60.0,30.0,49.0,59.0,66.0,71.0,55.0,66.0,66.0,63.0,52.0,84.0,76.0,90.0,73.0,71.0,85.0,77.0,82.0,72.0,68.0,58.0,46.0,49.0,57.0,75.0,46.0,64.0,53.0,55.0,67.0,79.0,88.0,72.0,58.0,28.0,39.0,44.0,47.0,92.0,98.0,72.0,83.0,25.0,37.0,82.0,75.0,55.0,69.0,80.0,82.0,71.0,64.0,50.0,96.0,71.0,71.0,74.0,75.0,82.0,86.0,79.0,85.0,83.0,72.0,68.0,55.0,40.0,49.0,76.0,82.0,83.0,78.0,70.0,108.0,81.0,54.0,22.0,40.0,41.0,59.0,42.0,48.0,68.0,70.0,95.0,120.0,75.0,52.0,32.0,33.0,21.0,69.0,57.0,52.0,55.0,48.0,47.0,91.0,60.0,68.0,54.0,62.0,65.0,75.0,74.0,73.0,71.0,87.0,61.0,57.0,75.0,83.0,73.0,104.0,86.0,112.0,82.0,74.0,72.0,53.0,54.0,27.0,35.0,61.0,65.0,70.0,70.0,6.0,26.0,21.0,42.0,71.0,87.0,32.0,45.0,88.0,65.0,74.0,62.0,68.0,65.0,55.0,40.0,38.0,28.0,34.0,34.0,42.0,47.0,78.0,47.0,72.0,78.0,61.0,79.0,106.0,75.0,95.0,68.0,70.0,49.0,54.0,69.0,73.0,85.0,69.0,71.0,56.0,64.0,77.0,84.0,79.0,90.0,86.0,79.0,34.0,27.0,29.0,37.0,46.0,55.0,53.0,48.0,48.0,58.0,58.0,52.0,61.0,58.0,42.0,75.0,83.0,60.0,63.0,39.0,33.0,52.0,46.0,55.0,29.0,34.0,51.0,54.0,64.0,90.0,63.0,59.0,91.0,62.0,77.0,87.0,74.0,39.0,44.0,32.0,84.0,53.0,32.0,41.0,46.0,45.0,48.0,68.0,78.0,41.0,45.0,54.0,72.0,61.0,70.0,62.0,54.0,71.0,80.0,92.0,89.0,73.0,99.0,85.0,83.0,92.0,79.0,67.0,68.0,78.0,90.0,72.0,80.0,95.0,78.0,75.0,48.0,47.0,61.0,27.0,72.0,58.0,86.0,70.0,76.0,75.0,82.0,84.0,55.0,65.0,86.0,73.0,69.0,74.0,73.0,83.0,72.0,53.0,72.0,78.0,97.0,89.0,90.0,86.0,86.0,89.0,59.0,84.0,61.0,46.0,72.0,92.0,94.0,84.0,72.0,72.0,98.0,67.0,76.0,72.0,81.0,85.0,46.0,112.0,69.0,68.0,71.0,94.0,65.0,61.0,45.0,49.0,65.0,61.0,68.0,84.0,88.0,88.0,57.0,73.0,61.0,60.0,60.0,22.0,40.0,62.0,81.0,79.0,76.0,45.0,59.0,63.0,69.0,81.0,111.0,105.0,77.0,63.0,48.0,65.0,32.0,55.0,73.0,75.0,75.0,73.0,80.0,101.0,83.0,68.0,96.0,80.0,83.0,62.0,106.0,89.0,99.0,79.0,97.0,64.0,48.0,50.0,71.0,72.0,70.0,75.0,58.0,62.0,50.0,65.0,56.0,113.0,91.0,98.0,75.0,76.0,143.0,91.0,59.0,63.0,61.0,57.0,83.0,84.0,66.0,69.0,3.0,50.0,58.0,69.0,52.0,70.0,70.0,66.0,69.0,52.0,61.0,59.0,61.0,74.0,70.0,77.0,77.0,82.0,59.0,64.0,84.0,79.0,44.0,47.0,56.0,67.0,69.0,82.0,84.0,68.0,61.0,69.0,76.0,66.0,75.0,79.0,61.0,57.0,54.0,49.0,41.0,49.0,59.0,66.0,59.0,43.0,51.0,28.0,75.0,87.0,61.0,76.0,74.0,48.0,48.0,67.0,34.0,42.0,84.0,52.0,57.0,66.0,64.0,67.0,30.0,28.0,73.0,81.0,66.0,87.0,38.0,36.0,89.0,72.0,84.0,65.0,91.0,113.0,104.0,65.0,74.0,74.0,73.0,62.0,62.0,69.0,46.0,68.0,72.0,95.0,66.0,67.0,60.0,76.0,64.0,115.0,76.0,74.0,77.0,99.0,67.0,84.0,71.0,94.0,78.0,83.0,71.0,97.0,53.0,59.0,56.0,77.0,58.0,58.0,54.0,59.0,57.0,78.0,86.0,84.0,70.0,74.0,58.0,82.0,66.0,146.0,97.0,39.0,36.0,80.0,55.0,68.0,67.0,64.0,84.0,60.0,61.0,93.0,73.0,31.0,44.0,41.0,61.0,51.0,78.0,77.0,77.0,67.0,70.0,103.0,85.0,68.0,73.0,51.0,68.0,90.0,78.0,79.0,80.0,86.0,76.0,64.0,80.0,75.0,54.0,80.0,36.0,42.0,81.0,49.0,73.0,79.0,50.0,52.0,61.0,57.0,82.0,83.0,77.0,100.0,86.0,65.0,63.0,76.0,84.0,75.0,72.0,50.0,53.0,58.0,74.0,73.0,88.0,93.0,60.0,76.0,104.0,75.0,50.0,69.0,51.0,55.0,55.0,59.0,84.0,55.0,77.0,57.0,72.0,61.0,62.0,62.0,63.0,85.0,79.0,79.0,78.0,93.0,111.0,98.0,82.0,72.0,71.0,105.0,83.0,77.0,75.0,66.0,73.0,82.0,98.0,75.0,82.0,98.0,94.0,86.0,129.0,114.0,103.0,84.0,90.0,62.0,77.0,84.0,91.0,72.0,67.0,78.0,72.0,51.0,43.0,41.0,87.0,65.0,18.0,50.0,69.0,74.0,65.0,66.0,58.0,61.0,53.0,72.0,85.0,50.0,68.0,67.0,70.0,71.0,82.0,71.0,69.0,73.0,71.0,67.0,69.0,51.0,93.0,83.0,91.0,70.0,88.0,78.0,113.0,117.0,85.0,71.0,78.0,104.0,84.0,73.0,46.0,50.0,77.0,80.0,67.0,86.0,83.0,74.0,46.0,52.0,76.0,52.0,46.0,60.0,65.0,66.0,83.0,50.0,109.0,52.0,76.0,76.0,69.0,45.0,56.0,88.0,84.0,53.0,37.0,42.0,48.0,97.0,56.0,31.0,30.0,70.0,66.0,55.0,59.0,51.0,64.0,72.0,108.0,84.0,69.0,45.0,54.0,55.0,79.0,75.0,72.0,64.0,65.0,61.0,70.0,54.0,71.0,71.0,59.0,51.0,46.0,65.0,82.0,66.0,96.0,95.0,86.0,117.0,111.0,103.0,67.0,35.0,42.0,36.0,59.0,100.0,71.0,69.0,79.0,102.0,90.0,95.0,78.0,65.0,88.0,78.0,93.0,76.0,70.0,22.0,43.0,55.0,56.0,55.0,61.0,67.0,46.0,63.0,88.0,57.0,102.0,84.0,114.0,71.0,84.0,85.0,80.0,91.0,71.0,81.0,78.0,88.0,88.0,84.0,67.0,49.0,92.0,88.0,74.0,89.0,85.0,81.0,60.0,76.0,70.0,68.0,65.0,72.0,85.0,72.0,78.0,92.0,89.0,67.0,82.0,91.0,71.0,88.0,78.0,79.0,71.0,78.0,82.0,81.0,75.0,82.0,85.0,35.0,60.0,72.0,107.0,36.0,44.0,50.0,99.0,61.0,42.0,68.0,56.0,31.0,37.0,40.0,49.0,64.0,67.0,55.0,63.0,64.0,69.0,72.0,77.0,55.0,69.0,49.0,32.0,62.0,75.0,73.0,65.0,91.0,96.0,89.0,70.0,76.0,62.0,50.0,70.0,97.0,72.0,49.0,63.0,64.0,77.0,46.0,36.0,38.0,54.0,58.0,114.0,74.0,77.0,84.0,89.0,112.0,59.0,94.0,77.0,55.0,57.0,60.0,79.0,58.0,64.0,56.0,59.0,52.0,21.0,49.0,53.0,77.0,86.0,79.0,79.0,106.0,63.0,57.0,55.0,46.0,69.0,69.0,51.0,63.0,87.0,57.0,71.0,96.0,69.0,67.0,98.0,82.0,62.0,75.0,73.0,67.0,69.0,89.0,89.0,74.0,80.0,82.0,97.0,107.0,65.0,41.0,49.0,37.0,45.0,74.0,68.0,74.0,69.0,63.0,55.0,90.0,105.0,76.0,66.0,91.0,62.0,91.0,59.0,80.0,43.0,66.0,58.0,43.0,57.0,55.0,67.0,82.0,69.0,87.0,53.0,73.0,80.0,31.0,52.0,81.0,95.0,93.0,63.0,60.0,67.0,59.0,42.0,62.0,62.0,68.0,55.0,63.0,80.0,70.0,108.0,94.0,71.0,81.0,76.0,85.0,69.0,61.0,87.0,65.0,108.0,80.0,65.0,65.0,68.0,75.0,83.0,85.0,71.0,78.0,72.0,67.0,87.0,51.0,64.0,46.0,62.0,66.0,70.0,90.0,80.0,84.0,74.0,83.0,84.0,83.0,79.0,71.0,88.0,76.0,91.0,3.0,46.0,71.0,87.0,57.0,58.0,61.0,53.0,47.0,72.0,50.0,80.0,71.0,63.0,59.0,70.0,71.0,50.0,69.0,51.0,57.0,68.0,80.0,53.0,49.0,61.0,54.0,73.0,63.0,67.0,121.0,97.0,79.0,50.0,42.0,54.0,55.0,61.0,78.0,67.0,58.0,93.0,61.0,66.0,66.0,73.0,59.0,80.0,56.0,54.0,93.0,85.0,68.0,90.0,118.0,77.0,59.0,77.0,71.0,73.0,62.0,103.0,81.0,86.0,53.0,48.0,67.0,61.0,53.0,71.0,56.0,54.0,61.0,45.0,57.0,64.0,69.0,96.0,69.0,109.0,81.0,57.0,71.0,65.0,78.0,74.0,57.0,107.0,84.0,86.0,59.0,76.0,78.0,66.0,98.0,83.0,73.0,61.0,66.0,61.0,61.0,29.0,48.0,66.0,61.0,104.0,92.0,83.0,89.0,87.0,78.0,88.0,83.0,83.0,80.0,68.0,79.0,86.0,93.0,84.0,66.0,102.0,70.0,61.0,74.0,86.0,61.0,21.0,30.0,51.0,68.0,67.0,60.0,55.0,58.0,54.0,67.0,80.0,72.0,74.0,92.0,90.0,71.0,59.0,75.0,56.0,76.0,46.0,33.0,38.0,44.0,55.0,83.0,67.0,73.0,75.0,83.0,65.0,65.0,52.0,69.0,68.0,79.0,65.0,64.0,94.0,61.0,56.0,92.0,92.0,63.0,75.0,50.0,52.0,77.0,65.0,66.0,83.0,74.0,72.0,88.0,89.0,77.0,79.0,53.0,76.0,63.0,73.0,60.0,93.0,73.0,69.0,63.0,90.0,86.0,78.0,115.0,94.0,71.0,78.0,82.0,90.0,57.0,111.0,62.0,76.0,19.0,38.0,43.0,57.0,69.0,51.0,82.0,75.0,79.0,40.0,45.0,53.0,81.0,82.0,87.0,77.0,83.0,74.0,95.0,82.0,100.0,71.0,88.0,98.0,87.0,60.0,57.0,47.0,59.0,61.0,54.0,58.0,53.0,93.0,94.0,79.0,61.0,26.0,42.0,70.0,77.0,63.0,68.0,73.0,88.0,77.0,91.0,90.0,22.0,72.0,83.0,73.0,76.0,55.0,39.0,39.0,50.0,42.0,46.0,49.0,36.0,46.0,65.0,73.0,54.0,44.0,37.0,75.0,66.0,75.0,45.0,44.0,110.0,75.0,75.0,94.0,58.0,48.0,58.0,59.0,66.0,58.0,42.0,78.0,60.0,76.0,61.0,62.0,72.0,56.0,41.0,56.0,70.0,59.0,90.0,74.0,64.0,71.0,80.0,77.0,66.0,63.0,93.0,60.0,53.0,51.0,53.0,118.0,52.0,46.0,47.0,53.0,47.0,54.0,71.0,59.0,65.0,87.0,95.0,67.0,67.0,66.0,73.0,59.0,103.0,87.0,88.0,37.0,46.0,62.0,95.0,91.0,101.0,81.0,69.0,80.0,68.0,92.0,77.0,85.0,87.0,74.0,77.0,79.0,108.0,95.0,77.0,62.0,87.0,92.0,80.0,51.0,56.0,45.0,52.0,49.0,43.0,55.0,64.0,83.0,54.0,48.0,83.0,80.0,66.0,64.0,47.0,41.0,38.0,69.0,74.0,81.0,64.0,58.0,86.0,2.0,45.0,40.0,77.0,65.0,67.0,54.0,54.0,72.0,60.0,60.0,67.0,25.0,27.0,52.0,65.0,62.0,71.0,60.0,71.0,68.0,55.0,66.0,71.0,69.0,108.0,93.0,74.0,34.0,46.0,47.0,56.0,35.0,29.0,31.0,33.0,34.0,55.0,91.0,83.0,83.0,97.0,76.0,64.0,51.0,25.0,39.0,60.0,57.0,64.0,71.0,84.0,52.0,69.0,26.0,34.0,46.0,47.0,49.0,50.0,51.0,20.0,39.0,44.0,44.0,54.0,69.0,57.0,78.0,69.0,54.0,112.0,91.0,88.0,80.0,71.0,67.0,86.0,62.0,97.0,71.0,47.0,52.0,41.0,48.0,58.0,65.0,57.0,22.0,30.0,58.0,95.0,46.0,62.0,86.0,83.0,63.0,80.0,72.0,76.0,84.0,96.0,97.0,86.0,64.0,70.0,73.0,100.0,73.0,78.0,73.0,44.0,63.0,55.0,60.0,55.0,18.0,35.0,70.0,103.0,85.0,68.0,85.0,34.0,65.0,72.0,105.0,17.0,34.0,45.0,91.0,66.0,63.0,91.0,73.0,21.0,40.0,21.0,30.0,40.0,50.0,44.0,55.0,65.0,99.0,70.0,82.0,91.0,69.0,55.0,78.0,69.0,82.0,64.0,56.0,77.0,57.0,72.0,81.0,94.0,83.0,45.0,57.0,44.0,43.0,52.0,72.0,59.0,47.0,42.0,62.0,61.0,59.0,46.0,68.0,74.0,39.0,39.0,46.0,43.0,45.0,52.0,55.0,67.0,58.0,39.0,62.0,59.0,71.0,80.0,79.0,68.0,57.0,88.0,70.0,56.0,54.0,44.0,67.0,50.0,76.0,68.0,39.0,40.0,41.0,52.0,37.0,62.0,60.0,73.0,91.0,45.0,79.0,69.0,75.0,128.0,116.0,98.0,65.0,62.0,66.0,61.0,65.0,67.0,54.0,56.0,62.0,61.0,73.0,72.0,64.0,72.0,88.0,92.0,90.0,70.0,69.0,62.0,68.0,101.0,82.0,64.0,58.0,98.0,86.0,98.0,66.0,49.0,46.0,44.0,69.0,124.0,90.0,97.0,24.0,61.0,91.0,66.0,44.0,71.0,45.0,31.0,47.0,71.0,115.0,20.0,40.0,67.0,61.0,41.0,40.0,59.0,67.0,45.0,61.0,60.0,73.0,85.0,74.0,67.0,91.0,50.0,64.0,68.0,73.0,64.0,85.0,49.0,97.0,64.0,80.0,36.0,57.0,70.0,83.0,59.0,81.0,103.0,79.0,62.0,62.0,54.0,58.0,54.0,66.0,43.0,94.0,83.0,74.0,109.0,58.0,38.0,49.0,55.0,39.0,58.0,51.0,60.0,75.0,89.0,65.0,62.0,116.0,89.0,77.0,70.0,85.0,75.0,64.0,47.0,58.0,91.0,71.0,88.0,70.0,88.0,74.0,85.0,79.0,110.0,81.0,72.0,57.0,58.0,62.0,76.0,89.0,93.0,74.0,60.0,71.0,68.0,69.0,45.0,106.0,86.0,57.0,58.0,69.0,62.0,98.0,76.0,95.0,58.0,30.0,34.0,59.0,67.0,82.0,91.0,80.0,72.0,51.0,55.0,51.0,79.0,100.0,82.0,67.0,68.0,74.0,29.0,53.0,96.0,72.0,64.0,59.0,57.0,60.0,61.0,107.0,95.0,56.0,63.0,66.0,55.0,55.0,59.0,74.0,91.0,64.0,46.0,77.0,79.0,75.0,93.0,106.0,103.0,46.0,85.0,124.0,61.0,35.0,38.0,38.0,45.0,91.0,78.0,58.0,57.0,50.0,64.0,98.0,63.0,104.0,87.0,71.0,76.0,80.0,87.0,77.0,76.0,85.0,60.0,71.0,77.0,120.0,80.0,61.0,65.0,67.0,77.0,42.0,50.0,64.0,66.0,77.0,64.0,86.0,90.0,73.0,34.0,46.0,75.0,68.0,65.0,71.0,75.0,63.0,73.0,47.0,51.0,57.0,60.0,67.0,56.0,63.0,75.0,82.0,76.0,53.0,49.0,42.0,55.0,52.0,91.0,88.0,67.0,61.0,68.0,73.0,74.0,98.0,66.0,71.0,54.0,52.0,63.0,78.0,81.0,72.0,64.0,70.0,69.0,102.0,83.0,72.0,63.0,93.0,98.0,95.0,73.0,73.0,63.0,73.0,44.0,34.0,66.0,12.0,45.0,56.0,43.0,68.0,72.0,55.0,54.0,81.0,78.0,71.0,49.0,56.0,62.0,72.0,78.0,79.0,69.0,69.0,49.0,44.0,39.0,44.0,52.0,38.0,44.0,35.0,71.0,49.0,89.0,76.0,69.0,100.0,109.0,68.0,70.0,69.0,56.0,68.0,61.0,70.0,73.0,96.0,72.0,72.0,79.0,81.0,76.0,65.0,56.0,75.0,63.0,61.0,69.0,31.0,40.0,61.0,61.0,81.0,57.0,102.0,65.0,55.0,62.0,64.0,83.0,61.0,35.0,62.0,96.0,58.0,55.0,60.0,57.0,82.0,71.0,69.0,65.0,77.0,74.0,62.0,58.0,36.0,55.0,71.0,57.0,74.0,75.0,83.0,60.0,58.0,79.0,102.0,73.0,71.0,40.0,54.0,57.0,63.0,65.0,69.0,85.0,78.0,100.0,41.0,94.0,85.0,89.0,84.0,97.0,92.0,89.0,74.0,85.0,112.0,100.0,113.0,90.0,76.0,84.0,69.0,52.0,60.0,77.0,58.0,69.0,59.0,2.0,47.0,60.0,91.0,71.0,44.0,72.0,65.0,46.0,64.0,42.0,48.0,17.0,19.0,48.0,57.0,71.0,57.0,62.0,62.0,74.0,82.0,75.0,69.0,84.0,102.0,91.0,81.0,67.0,40.0,70.0,107.0,80.0,68.0,59.0,40.0,45.0,40.0,61.0,73.0,74.0,55.0,58.0,68.0,52.0,60.0,80.0,62.0,76.0,62.0,79.0,80.0,68.0,106.0,70.0,50.0,84.0,102.0,75.0,74.0,108.0,72.0,53.0,63.0,62.0,71.0,59.0,50.0,79.0,76.0,63.0,70.0,61.0,74.0,61.0,69.0,80.0,62.0,71.0,89.0,58.0,95.0,71.0,66.0,61.0,75.0,88.0,72.0,71.0,58.0,69.0,85.0,77.0,70.0,61.0,67.0,72.0,84.0,87.0,73.0,79.0,72.0,96.0,69.0,63.0,51.0,66.0,69.0,70.0,65.0,53.0,57.0,45.0,54.0,64.0,81.0,88.0,105.0,80.0,85.0,83.0,75.0,87.0,71.0,44.0,47.0,47.0,2.0,28.0,35.0,32.0,62.0,64.0,81.0,66.0,61.0,32.0,34.0,98.0,50.0,69.0,82.0,88.0,111.0,73.0,85.0,61.0,49.0,93.0,97.0,86.0,82.0,80.0,82.0,66.0,66.0,48.0,56.0,58.0,52.0,42.0,115.0,93.0,96.0,72.0,82.0,64.0,49.0,38.0,33.0,43.0,53.0,45.0,66.0,80.0,83.0,56.0,58.0,50.0,68.0,76.0,57.0,39.0,58.0,62.0,66.0,60.0,76.0,65.0,62.0,74.0,78.0,112.0,82.0,66.0,35.0,44.0,36.0,34.0,43.0,36.0,53.0,48.0,43.0,45.0,57.0,53.0,49.0,69.0,64.0,95.0,85.0,75.0,59.0,69.0,60.0,45.0,50.0,36.0,53.0,44.0,45.0,50.0,55.0,71.0,78.0,78.0,70.0,66.0,71.0,73.0,78.0,77.0,64.0,76.0,36.0,36.0,48.0,61.0,71.0,82.0,57.0,84.0,71.0,77.0,70.0,75.0,83.0,89.0,71.0,50.0,52.0,60.0,98.0,25.0,66.0,41.0,42.0,57.0,65.0,59.0,77.0,67.0,77.0,75.0,49.0,80.0,70.0,69.0,65.0,64.0,89.0,64.0,47.0,49.0,53.0,46.0,63.0,55.0,61.0,84.0,87.0,87.0,78.0,79.0,82.0,72.0,85.0,67.0,63.0,97.0,85.0,95.0,127.0,89.0,81.0,70.0,68.0,69.0,76.0,68.0,59.0,45.0,63.0,58.0,89.0,68.0,65.0,52.0,74.0,85.0,73.0,68.0,59.0,70.0,62.0,55.0,49.0,59.0,66.0,77.0,90.0,50.0,70.0,73.0,56.0,71.0,72.0,76.0,68.0,55.0,60.0,68.0,82.0,86.0,115.0,94.0,96.0,50.0,42.0,56.0,66.0,68.0,81.0,57.0,43.0,47.0,73.0,63.0,84.0,61.0,80.0,66.0,48.0,42.0,53.0,38.0,48.0,52.0,62.0,57.0,44.0,61.0,95.0,62.0,68.0,64.0,65.0,92.0,95.0,75.0,76.0,67.0,76.0,80.0,67.0,77.0,77.0,72.0,66.0,60.0,21.0,29.0,46.0,42.0,43.0,61.0,64.0,54.0,60.0,73.0,52.0,64.0,57.0,81.0,69.0,57.0,59.0,60.0,49.0,50.0,51.0,43.0,27.0,37.0,45.0,49.0,62.0,60.0,90.0,82.0,84.0,49.0,57.0,67.0,86.0,90.0,58.0,52.0,22.0,23.0,36.0,36.0,35.0,46.0,50.0,49.0,42.0,48.0,29.0,33.0,53.0,46.0,42.0,58.0,61.0,55.0,69.0,48.0,51.0,56.0,47.0,61.0,40.0,46.0,49.0,47.0,72.0,83.0,80.0,74.0,90.0,77.0,63.0,74.0,73.0,69.0,55.0,49.0,105.0,67.0,65.0,54.0,53.0,64.0,61.0,73.0,57.0,60.0,74.0,89.0,77.0,77.0,95.0,89.0,85.0,76.0,85.0,68.0,66.0,52.0,64.0,70.0,84.0,78.0,94.0,60.0,37.0,45.0,49.0,56.0,21.0,32.0,58.0,48.0,57.0,59.0,55.0,71.0,78.0,71.0,57.0,56.0,48.0,63.0,52.0,56.0,64.0,3.0,62.0,62.0,56.0,75.0,94.0,58.0,86.0,63.0,27.0,37.0,55.0,38.0,41.0,41.0,26.0,24.0,42.0,37.0,50.0,57.0,74.0,70.0,27.0,45.0,60.0,79.0,84.0,62.0,50.0,59.0,59.0,56.0,63.0,66.0,68.0,96.0,75.0,149.0,71.0,37.0,50.0,44.0,49.0,48.0,45.0,21.0,48.0,67.0,55.0,53.0,79.0,63.0,59.0,90.0,87.0,71.0,48.0,48.0,58.0,46.0,47.0,48.0,42.0,44.0,38.0,93.0,57.0,62.0,48.0,101.0,67.0,68.0,52.0,82.0,59.0,80.0,78.0,69.0,83.0,72.0,64.0,72.0,82.0,51.0,91.0,81.0,88.0,66.0,81.0,69.0,113.0,70.0,52.0,65.0,70.0,73.0,63.0,83.0,60.0,73.0,66.0,73.0,85.0,86.0,82.0,61.0,44.0,93.0,75.0,35.0,42.0,62.0,25.0,37.0,44.0,48.0,65.0,56.0,61.0,71.0,112.0,94.0,64.0,130.0,121.0,95.0,31.0,54.0,30.0,31.0,42.0,45.0,50.0,76.0,76.0,77.0,87.0,96.0,69.0,91.0,94.0,72.0,85.0,63.0,69.0,83.0,70.0,75.0,87.0,58.0,57.0,70.0,68.0,70.0,81.0,82.0,66.0,101.0,85.0,80.0,67.0,101.0,72.0,29.0,40.0,57.0,68.0,67.0,59.0,62.0,92.0,58.0,62.0,84.0,71.0,72.0,68.0,79.0,83.0,68.0,79.0,72.0,74.0,85.0,68.0,80.0,86.0,63.0,77.0,81.0,75.0,57.0,75.0,82.0,58.0,62.0,56.0,66.0,75.0,63.0,71.0,73.0,96.0,77.0,58.0,47.0,43.0,36.0,47.0,50.0,58.0,69.0,80.0,62.0,66.0,38.0,40.0,32.0,47.0,52.0,57.0,40.0,46.0,55.0,55.0,70.0,63.0,83.0,138.0,83.0,81.0,86.0,87.0,66.0,53.0,52.0,48.0,36.0,75.0,79.0,76.0,94.0,66.0,64.0,110.0,92.0,87.0,113.0,85.0,63.0,51.0,38.0,46.0,33.0,61.0,72.0,49.0,51.0,53.0,68.0,59.0,54.0,35.0,71.0,64.0,70.0,69.0,73.0,41.0,33.0,29.0,30.0,74.0,85.0,78.0,29.0,48.0,54.0,60.0,66.0,75.0,81.0,73.0,49.0,66.0,63.0,37.0,42.0,62.0,45.0,58.0,49.0,69.0,74.0,49.0,37.0,82.0,54.0,27.0,70.0,49.0,38.0,49.0,56.0,113.0,63.0,59.0,69.0,68.0,44.0,86.0,86.0,118.0,68.0,54.0,94.0,96.0,65.0,101.0,80.0,62.0,72.0,70.0,42.0,70.0,72.0,80.0,76.0,74.0,108.0,56.0,80.0,106.0,74.0,110.0,72.0,79.0,59.0,51.0,82.0,82.0,83.0,89.0,63.0,88.0,81.0,40.0,94.0,83.0,109.0,56.0,77.0,77.0,111.0,80.0,112.0,94.0,105.0,113.0,82.0,75.0,67.0,79.0,88.0,86.0,77.0,81.0,80.0,93.0,85.0,91.0,83.0,88.0,85.0,130.0,89.0,77.0,132.0,78.0,85.0,2.0,46.0,63.0,77.0,83.0,113.0,106.0,56.0,80.0,77.0,58.0,60.0,61.0,67.0,102.0,114.0,95.0,92.0,70.0,89.0,106.0,66.0,39.0,39.0,73.0,60.0,116.0,69.0,42.0,61.0,70.0,63.0,39.0,66.0,63.0,76.0,66.0,61.0,48.0,132.0,92.0,66.0,88.0,109.0,63.0,81.0,81.0,44.0,89.0,84.0,43.0,102.0,84.0,67.0,66.0,102.0,61.0,79.0,82.0,82.0,64.0,52.0,81.0,80.0,120.0,85.0,91.0,86.0,122.0,146.0,92.0,72.0,67.0,55.0,62.0,51.0,103.0,119.0,83.0,63.0,69.0,97.0,104.0,109.0,99.0,90.0,93.0,93.0,67.0,81.0,78.0,80.0,82.0,72.0,77.0,80.0,100.0,93.0,70.0,63.0,84.0,46.0,112.0,89.0,77.0,102.0,66.0,69.0,62.0,74.0,83.0,80.0,73.0,67.0,70.0,74.0,78.0,81.0,80.0,77.0,73.0,75.0,74.0,88.0,86.0,121.0,86.0,40.0,85.0,56.0,73.0,74.0,110.0,60.0,40.0,72.0,75.0,74.0,74.0,72.0,68.0,64.0,63.0,62.0,61.0,45.0,77.0,60.0,96.0,72.0,51.0,65.0,78.0,119.0,97.0,58.0,134.0,69.0,55.0,75.0,73.0,71.0,77.0,74.0,73.0,72.0,76.0,58.0,126.0,86.0,43.0,62.0,67.0,67.0,71.0,69.0,71.0,55.0,54.0,56.0,95.0,109.0,78.0,61.0,78.0,94.0,105.0,106.0,104.0,114.0,83.0,123.0,43.0,51.0,67.0,66.0,65.0,70.0,71.0,64.0,63.0,63.0,69.0,69.0,82.0,45.0,69.0,81.0,85.0,86.0,76.0,46.0,61.0,53.0,92.0,49.0,53.0,72.0,68.0,68.0,70.0,74.0,68.0,70.0,67.0,73.0,79.0,76.0,81.0,85.0,103.0,54.0,121.0,117.0,69.0,73.0,74.0,89.0,53.0,54.0,65.0,67.0,71.0,70.0,74.0,71.0,72.0,73.0,75.0,77.0,69.0,93.0,97.0,97.0,36.0,43.0,61.0,83.0,88.0,84.0,56.0,111.0,53.0,32.0,70.0,79.0,78.0,78.0,74.0,70.0,52.0,70.0,64.0,125.0,106.0,73.0,78.0,73.0,83.0,84.0,78.0,68.0,65.0,58.0,57.0,105.0,107.0,75.0,62.0,74.0,94.0,113.0,99.0,102.0,98.0,80.0,124.0,60.0,56.0,76.0,72.0,68.0,76.0,76.0,72.0,78.0,84.0,74.0,69.0,85.0,47.0,67.0,78.0,91.0,86.0,78.0,38.0,57.0,47.0,101.0,65.0,65.0,75.0,66.0,70.0,70.0,78.0,78.0,74.0,69.0,74.0,74.0,76.0,80.0,80.0,55.0,103.0,81.0,85.0,67.0,69.0,49.0,92.0,57.0,59.0,65.0,67.0,71.0,72.0,70.0,73.0,69.0,68.0,69.0,72.0,70.0,91.0,80.0,77.0,82.0,51.0,69.0,80.0,84.0,123.0,92.0,81.0,93.0,47.0,64.0,67.0,68.0,76.0,74.0,73.0,74.0,95.0,54.0,80.0,70.0,66.0,23.0,72.0,78.0,71.0,68.0,62.0,67.0,45.0,76.0,57.0,104.0,115.0,89.0,62.0,85.0,85.0,126.0,112.0,117.0,94.0,93.0,123.0,49.0,52.0,69.0,73.0,77.0,82.0,84.0,79.0,82.0,77.0,67.0,65.0,94.0,54.0,63.0,71.0,90.0,78.0,70.0,42.0,59.0,53.0,120.0,66.0,67.0,69.0,70.0,73.0,78.0,76.0,73.0,69.0,66.0,70.0,74.0,69.0,83.0,83.0,45.0,87.0,73.0,100.0,81.0,55.0,63.0,63.0,82.0,40.0,87.0,53.0,66.0,51.0,101.0,45.0,70.0,73.0,72.0,75.0,76.0,78.0,76.0,68.0,68.0,72.0,68.0,82.0,69.0,72.0,89.0,82.0,54.0,87.0,77.0,83.0,117.0,104.0,65.0,103.0,42.0,60.0,67.0,69.0,72.0,80.0,77.0,80.0,91.0,75.0,66.0,98.0,66.0,66.0,59.0,60.0,72.0,69.0,66.0,70.0,54.0,88.0,93.0,136.0,123.0,82.0,78.0,11.0,38.0,112.0,74.0,57.0,72.0,73.0,111.0,49.0,35.0,60.0,75.0,74.0,68.0,66.0,63.0,61.0,59.0,55.0,56.0,48.0,55.0,55.0,60.0,83.0,67.0,65.0,47.0,63.0,49.0,124.0,64.0,62.0,67.0,70.0,67.0,71.0,74.0,74.0,71.0,73.0,72.0,75.0,70.0,84.0,88.0,69.0,55.0,110.0,79.0,68.0,62.0,114.0,61.0,56.0,63.0,62.0,65.0,73.0,77.0,75.0,73.0,68.0,64.0,66.0,59.0,65.0,62.0,88.0,70.0,61.0,77.0,75.0,116.0,103.0,56.0,116.0,39.0,51.0,60.0,57.0,62.0,68.0,68.0,75.0,84.0,72.0,56.0,107.0,66.0,57.0,50.0,45.0,58.0,54.0,60.0,61.0,59.0,55.0,58.0,145.0,114.0,71.0,68.0,81.0,89.0,108.0,113.0,90.0,107.0,112.0,84.0,52.0,66.0,62.0,63.0,64.0,67.0,67.0,72.0,72.0,75.0,76.0,82.0,81.0,66.0,135.0,30.0,74.0,60.0,67.0,75.0,56.0,65.0,101.0,49.0,35.0,77.0,82.0,83.0,73.0,67.0,58.0,53.0,54.0,55.0,59.0,44.0,84.0,76.0,62.0,64.0,102.0,65.0,74.0,62.0,129.0,79.0,61.0,70.0,71.0,67.0,68.0,76.0,72.0,76.0,75.0,73.0,73.0,71.0,77.0,62.0,80.0,78.0,61.0,73.0,79.0,109.0,93.0,65.0,116.0,49.0,42.0,59.0,62.0,69.0,70.0,75.0,71.0,86.0,64.0,56.0,111.0,79.0,44.0,49.0,50.0,54.0,60.0,62.0,63.0,51.0,59.0,52.0,101.0,111.0,79.0,65.0,75.0,94.0,103.0,104.0,104.0,106.0,97.0,124.0,48.0,54.0,63.0,61.0,61.0,68.0,67.0,64.0,64.0,67.0,72.0,72.0,73.0,49.0,70.0,105.0,113.0,128.0,75.0,52.0,67.0,81.0,93.0,60.0,55.0,68.0,69.0,72.0,77.0,74.0,75.0,74.0,74.0,76.0,81.0,89.0,91.0,130.0,36.0,50.0,84.0,60.0,76.0,67.0,122.0,62.0,38.0,83.0,86.0,79.0,75.0,76.0,71.0,62.0,60.0,64.0,65.0,50.0,79.0,59.0,94.0,69.0,55.0,64.0,77.0,111.0,97.0,54.0,130.0,56.0,60.0,75.0,74.0,71.0,75.0,76.0,73.0,66.0,74.0,57.0,120.0,76.0,55.0,66.0,66.0,66.0,70.0,68.0,65.0,52.0,57.0,55.0,98.0,114.0,78.0,63.0,78.0,94.0,107.0,105.0,101.0,110.0,85.0,126.0,47.0,53.0,67.0,67.0,65.0,67.0,69.0,65.0,66.0,64.0,67.0,64.0,94.0,45.0,65.0,80.0,88.0,87.0,69.0,47.0,60.0,56.0,102.0,50.0,58.0,74.0,67.0,66.0,69.0,72.0,69.0,70.0,69.0,70.0,81.0,83.0,86.0,83.0,73.0,107.0,92.0,97.0,71.0,68.0,71.0,92.0,53.0,56.0,66.0,70.0,70.0,73.0,73.0,72.0,70.0,75.0,74.0,81.0,72.0,95.0,103.0],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f6b7e46a-b4a7-43e6-a872-6eafea55f688');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l0 = (features_sae_encoded[:, 1:] > 0).float().sum(-1).detach()\n",
    "print(\"average l0\", l0.mean().item())\n",
    "px.histogram(l0.flatten().cpu().numpy()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig 3.562199831008911\n",
      "reconstr 3.764155387878418\n",
      "Zero 11.146592140197754\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import utils\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# next we want to do a reconstruction test.\n",
    "def reconstr_hook(activation, hook, sae_out):\n",
    "    return sae_out\n",
    "\n",
    "\n",
    "def zero_abl_hook(activation, hook):\n",
    "    return torch.zeros_like(activation)\n",
    "\n",
    "\n",
    "print(\"Orig\", model_gpt2(inputs, return_type=\"loss\").item())\n",
    "print(\n",
    "    \"reconstr\",\n",
    "    model_gpt2.run_with_hooks(\n",
    "        inputs,\n",
    "        fwd_hooks=[\n",
    "            (\n",
    "                sae.cfg.metadata.hook_name,\n",
    "                partial(reconstr_hook, sae_out=sae_decoded),\n",
    "            )\n",
    "        ],\n",
    "        return_type=\"loss\",\n",
    "    ).item(),\n",
    ")\n",
    "print(\n",
    "    \"Zero\",\n",
    "    model_gpt2.run_with_hooks(\n",
    "        inputs,\n",
    "        return_type=\"loss\",\n",
    "        fwd_hooks=[(sae.cfg.metadata.hook_name, zero_abl_hook)],\n",
    "    ).item(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'When', ' Bob', ' and', ' Mary', ' went', ' to', ' the', ' shop', ',', ' Bob', ' gave', ' the', ' bag', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17.42</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58.87</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m17.42\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m58.87\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.42 Prob: 58.87% Token: | Mary|\n",
      "Top 1th token. Logit: 15.36 Prob:  7.50% Token: | the|\n",
      "Top 2th token. Logit: 14.80 Prob:  4.27% Token: | them|\n",
      "Top 3th token. Logit: 14.75 Prob:  4.06% Token: | his|\n",
      "Top 4th token. Logit: 14.28 Prob:  2.54% Token: | her|\n",
      "Top 5th token. Logit: 14.23 Prob:  2.42% Token: | a|\n",
      "Top 6th token. Logit: 13.85 Prob:  1.66% Token: | their|\n",
      "Top 7th token. Logit: 13.37 Prob:  1.02% Token: | him|\n",
      "Top 8th token. Logit: 13.09 Prob:  0.77% Token: | Mrs|\n",
      "Top 9th token. Logit: 13.03 Prob:  0.73% Token: | Bob|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"When Bob and Mary went to the shop, Bob gave the bag to\"\n",
    "answer = \"Mary\"\n",
    "utils.test_prompt(prompt, answer, model_gpt2, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model_gpt2.to_tokens(prompt)\n",
    "\n",
    "logits, cache = model_gpt2.run_with_cache(prompt, prepend_bos=True)\n",
    "\n",
    "hook_name = sae.cfg.metadata.hook_name\n",
    "\n",
    "sae_out = sae(cache[hook_name])\n",
    "\n",
    "orig_loss = model_gpt2(tokens, return_type=\"loss\").item()\n",
    "tweaked_loss = model_gpt2.run_with_hooks(tokens, return_type=\"loss\", fwd_hooks=[(hook_name, partial(reconstr_hook, sae_out=sae_out))]).item()\n",
    "zeros_loss = model_gpt2.run_with_hooks(tokens, return_type=\"loss\", fwd_hooks=[(hook_name, zero_abl_hook)]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.02357816696167\n",
      "3.921599864959717\n",
      "11.242877006530762\n"
     ]
    }
   ],
   "source": [
    "print(orig_loss)\n",
    "print(tweaked_loss)\n",
    "print(zeros_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'When', ' Bob', ' and', ' Mary', ' went', ' to', ' the', ' shop', ',', ' Bob', ' gave', ' the', ' bag', ' to']\n",
      "Tokenized answer: [' Mary']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.45</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16.95</span><span style=\"font-weight: bold\">% Token: | Mary|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m15.45\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m16.95\u001b[0m\u001b[1m% Token: | Mary|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.45 Prob: 16.95% Token: | Mary|\n",
      "Top 1th token. Logit: 15.15 Prob: 12.60% Token: | her|\n",
      "Top 2th token. Logit: 15.01 Prob: 11.01% Token: | them|\n",
      "Top 3th token. Logit: 14.79 Prob:  8.78% Token: | the|\n",
      "Top 4th token. Logit: 14.34 Prob:  5.61% Token: | Bob|\n",
      "Top 5th token. Logit: 13.95 Prob:  3.79% Token: | a|\n",
      "Top 6th token. Logit: 13.92 Prob:  3.68% Token: | their|\n",
      "Top 7th token. Logit: 13.39 Prob:  2.18% Token: | him|\n",
      "Top 8th token. Logit: 13.08 Prob:  1.59% Token: | his|\n",
      "Top 9th token. Logit: 12.76 Prob:  1.16% Token: | me|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Mary'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Mary'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with model_gpt2.hooks(fwd_hooks=[\n",
    "    (hook_name, partial(reconstr_hook, sae_out=sae_out))\n",
    "]):\n",
    "    utils.test_prompt(prompt, answer, model_gpt2, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://neuronpedia.org/quick-list/?name=temporary_list&features=%5B%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%220%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%221%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%222%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%223%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%224%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%225%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%226%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%227%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%228%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%229%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2210%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2211%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2212%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2213%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2214%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2215%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2216%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2217%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2218%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2219%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2220%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2221%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2222%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2223%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2224%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2225%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2226%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2227%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2228%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2229%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2230%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2231%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2232%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2233%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2234%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2235%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2236%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2237%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2238%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2239%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2240%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2241%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2242%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2243%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2244%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2245%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2246%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2247%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2248%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2249%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2250%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2251%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2252%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2253%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2254%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2255%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2256%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2257%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2258%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2259%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2260%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2261%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2262%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2263%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2264%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2265%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2266%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2267%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2268%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2269%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2270%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2271%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2272%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2273%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2274%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2275%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2276%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2277%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2278%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2279%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2280%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2281%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2282%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2283%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2284%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2285%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2286%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2287%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2288%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2289%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2290%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2291%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2292%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2293%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2294%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2295%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2296%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2297%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2298%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2299%22%7D%5D\n"
     ]
    }
   ],
   "source": [
    "test_feature_idx_gpt = list(range(100))\n",
    "\n",
    "neuronpedia_quick_list = get_neuronpedia_quick_list(sae, test_feature_idx_gpt)\n",
    "\n",
    "print(neuronpedia_quick_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I'd like to read a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd like to read a bit about the history of the \"Pizza Hut\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_gpt2, prompt, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model_gpt2.run_with_cache(prompt)\n",
    "with torch.no_grad():\n",
    "  sae_encoded = sae.encode(cache[sae.cfg.metadata.hook_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f26_direc = sae.W_dec[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17.3299, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sae_encoded[sae_encoded != 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 24576])\n"
     ]
    }
   ],
   "source": [
    "print(sae_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sae_encoded[0][-1][26] = 50\n",
    "print(sae_encoded[0][-1][26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sae = sae.decode(sae_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd like to read a little little little little little little little little little little\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def reconstr_hook(activation, hook, sae_out):\n",
    "    return sae_out\n",
    "\n",
    "with model_gpt2.hooks(fwd_hooks=[\n",
    "    (sae.cfg.metadata.hook_name, partial(reconstr_hook, sae_out=decoded_sae))\n",
    "]):\n",
    "    print(generate_text(model_gpt2, prompt, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, sentence, tokens):\n",
    "  for i in range(tokens):\n",
    "    logits = model(sentence)\n",
    "    maxed = torch.argmax(logits[0, -1])\n",
    "    next = model.tokenizer.decode(maxed)\n",
    "    sentence += next\n",
    "  return sentence\n",
    "\n",
    "def reconstr_hook_steer(activation, hook, sae_out, strenght):\n",
    "    activation[:, -1, :] += sae_out * strenght\n",
    "    return activation\n",
    "\n",
    "def steer_output(model, sae, prompt, token, feature_to_steer, strengh):\n",
    "  steering_vector = sae.W_dec[feature_to_steer]\n",
    "  with model.hooks(fwd_hooks=[\n",
    "    (sae.cfg.metadata.hook_name, partial(reconstr_hook_steer, sae_out=steering_vector, strenght = strengh))\n",
    "]):\n",
    "    print(generate_text(model, prompt, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I work in a small factory in a small town in the middle of the city. I have a small shop and a\n"
     ]
    }
   ],
   "source": [
    "steer_output(model_gpt2, sae, \"I work in a\", 20, 34, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' love', ' you', ' I', ' love', ' you', ' so', ' much']\n",
      "torch.Size([1, 8, 24576])\n"
     ]
    }
   ],
   "source": [
    "# Find feature love\n",
    "#prompt = \"I love you so much, my heart if full of love.\"\n",
    "prompt=\"I love you I love you so much\"\n",
    "print(model_gpt2.to_str_tokens(prompt, prepend_bos=False))\n",
    "#prompt = \"Love\"\n",
    "_, cache = model_gpt2.run_with_cache(prompt, prepend_bos=False)\n",
    "love_pre = cache[sae.cfg.metadata.hook_name]\n",
    "love_encoded = sae.encode(love_pre)\n",
    "print(love_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24576])\n"
     ]
    }
   ],
   "source": [
    "maxes = torch.max(love_encoded[0], dim=0)\n",
    "print(maxes.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11978, 10666, 16087,  5590, 12457, 14635,  2212, 12918, 16850, 16269])\n",
      "https://neuronpedia.org/quick-list/?name=temporary_list&features=%5B%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2211978%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2210666%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2216087%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%225590%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2212457%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2214635%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%222212%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2212918%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2216850%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2216269%22%7D%5D\n"
     ]
    }
   ],
   "source": [
    "\n",
    "maxes_indice = torch.topk(love_encoded[0][-4], 10).indices\n",
    "print(maxes_indice)\n",
    "neuronpedia_quick_list = get_neuronpedia_quick_list(sae, maxes_indice.tolist())\n",
    "\n",
    "print(neuronpedia_quick_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to make this a post about the game and the game itself. I want to make this a post about\n"
     ]
    }
   ],
   "source": [
    "steer_output(model_gpt2, sae, \"I want to\", 20, 11978, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24576, 768])\n",
      "torch.Size([24576])\n",
      "tensor([10565, 21659, 20431, 18637, 14046,   501,  1520,  8954, 20184, 18525])\n",
      "https://neuronpedia.org/quick-list/?name=temporary_list&features=%5B%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2210565%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2221659%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2220431%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2218637%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2214046%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%22501%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%221520%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%228954%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2220184%22%7D%2C%20%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2218525%22%7D%5D\n"
     ]
    }
   ],
   "source": [
    "print(sae.W_dec.shape)\n",
    "word = \"love\"\n",
    "\n",
    "token_love = model_gpt2.tokenizer.encode(word)\n",
    "love_embedding = model_gpt2.W_E[token_love][0]\n",
    "\n",
    "res = sae.W_dec @ love_embedding\n",
    "print(res.shape)\n",
    "\n",
    "maxes_indice = torch.topk(res, 10).indices\n",
    "print(maxes_indice)\n",
    "neuronpedia_quick_list = get_neuronpedia_quick_list(sae, maxes_indice.tolist())\n",
    "\n",
    "print(neuronpedia_quick_list)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
